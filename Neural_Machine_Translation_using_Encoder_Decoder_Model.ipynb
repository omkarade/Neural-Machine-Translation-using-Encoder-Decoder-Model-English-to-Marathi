{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UNbUI3RtvQ4aPAulHUgsGU0b7o62FoZA",
      "authorship_tag": "ABX9TyNQcOtt6NZMAUjy0Yo3lmp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarade/Neural-Machine-Translation-using-Encoder-Decoder-Model-English-to-Marathi/blob/main/Neural_Machine_Translation_using_Encoder_Decoder_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFkxkeIZySdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n"
      ],
      "metadata": {
        "id": "IGeATpabyUaO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing:**"
      ],
      "metadata": {
        "id": "X442ocR6XDzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[data source](http://www.manythings.org/anki/ )"
      ],
      "metadata": {
        "id": "0IGFs_PlZ67x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines= pd.read_table('/mar.txt', names=['eng','mar', 'del'])\n",
        "lines=lines.drop(columns='del')\n",
        "# Lowercase all characters\n",
        "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "lines.mar=lines.mar.apply(lambda x: x.lower())\n",
        "# Remove quotes\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines.mar=lines.mar.apply(lambda x: re.sub(\"'\", '', x))\n",
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines.mar=lines.mar.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
        "lines.mar=lines.mar.apply(lambda x: x.strip())\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines.mar=lines.mar.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "# Add start and end tokens to target sequences\n",
        "lines.mar = lines.mar.apply(lambda x : 'START_ '+ x + ' _END')\n"
      ],
      "metadata": {
        "id": "WBQ5OmibQLUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Vocabulary**"
      ],
      "metadata": {
        "id": "ONB7mUwqXTsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "# Vocabulary of Marathi \n",
        "all_marathi_words=set()\n",
        "for mar in lines.mar:\n",
        "    for word in mar.split():\n",
        "        if word not in all_marathi_words:\n",
        "            all_marathi_words.add(word)\n",
        "\n"
      ],
      "metadata": {
        "id": "ONPZbroYzYHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculating maximum length of source and target sequence ,building input_token and target_token.**"
      ],
      "metadata": {
        "id": "2F_9XzJZXdEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in lines.eng:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "max_length_src"
      ],
      "metadata": {
        "id": "p9rce1enXfRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in lines.mar:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "max_length_tar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkhFodLGzYM6",
        "outputId": "04b33baf-ceeb-412a-cb62-0c0492482c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_marathi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_marathi_words)\n",
        "num_encoder_tokens, num_decoder_tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBWSyRihzYPY",
        "outputId": "beda8ba2-4868-4ad7-d21c-e0fcb42d83e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5823, 14273)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgCCrD-iyUjW",
        "outputId": "64341f21-c719-4ce3-cfb5-515c95249795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14274"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
        "lines = shuffle(lines)\n",
        "lines.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Uh63fVG1yUmF",
        "outputId": "8cfac098-6deb-4114-aba4-d9f114541698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    eng  \\\n",
              "26637         the train finally arrived   \n",
              "34353    everything tom does is illegal   \n",
              "9586                   wheres your baby   \n",
              "15541               lets go and ask tom   \n",
              "37050  that company produces microchips   \n",
              "15877              they are vegetarians   \n",
              "37452  wine is poetry put into a bottle   \n",
              "29560       he is staying with his aunt   \n",
              "28284        it is fun to play baseball   \n",
              "36860   ill go even if it rains heavily   \n",
              "\n",
              "                                                     mar  \n",
              "26637                   START_ ट्रेन शेवटी पोहोचलीच _END  \n",
              "34353  START_ टॉम जे करतो ते सर्वकाही गैरकायदेशीर असत...  \n",
              "9586                       START_ तुझं बाळ कुठे आहे _END  \n",
              "15541                    START_ जाऊन टॉमला विचारूया _END  \n",
              "37050       START_ ती कंपनी मायक्रोचिप उत्पन्न करते _END  \n",
              "15877                     START_ त्या शाकाहारी आहेत _END  \n",
              "37452       START_ वाईन म्हणजे बाटलीत टाकलेलं काव्य _END  \n",
              "29560           START_ तो त्याच्या मामीबरोबर राहतोय _END  \n",
              "28284               START_ बेसबॉल खेळण्यात मजा येते _END  \n",
              "36860       START_ जोरजोरात पाऊस पडला तरीही मी जाईन _END  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f83cab57-1094-4fea-be2d-44f701e88cf2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>mar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26637</th>\n",
              "      <td>the train finally arrived</td>\n",
              "      <td>START_ ट्रेन शेवटी पोहोचलीच _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34353</th>\n",
              "      <td>everything tom does is illegal</td>\n",
              "      <td>START_ टॉम जे करतो ते सर्वकाही गैरकायदेशीर असत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9586</th>\n",
              "      <td>wheres your baby</td>\n",
              "      <td>START_ तुझं बाळ कुठे आहे _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15541</th>\n",
              "      <td>lets go and ask tom</td>\n",
              "      <td>START_ जाऊन टॉमला विचारूया _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37050</th>\n",
              "      <td>that company produces microchips</td>\n",
              "      <td>START_ ती कंपनी मायक्रोचिप उत्पन्न करते _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15877</th>\n",
              "      <td>they are vegetarians</td>\n",
              "      <td>START_ त्या शाकाहारी आहेत _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37452</th>\n",
              "      <td>wine is poetry put into a bottle</td>\n",
              "      <td>START_ वाईन म्हणजे बाटलीत टाकलेलं काव्य _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29560</th>\n",
              "      <td>he is staying with his aunt</td>\n",
              "      <td>START_ तो त्याच्या मामीबरोबर राहतोय _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28284</th>\n",
              "      <td>it is fun to play baseball</td>\n",
              "      <td>START_ बेसबॉल खेळण्यात मजा येते _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36860</th>\n",
              "      <td>ill go even if it rains heavily</td>\n",
              "      <td>START_ जोरजोरात पाऊस पडला तरीही मी जाईन _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f83cab57-1094-4fea-be2d-44f701e88cf2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f83cab57-1094-4fea-be2d-44f701e88cf2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f83cab57-1094-4fea-be2d-44f701e88cf2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train test Split**"
      ],
      "metadata": {
        "id": "FMg5e58fXhky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = lines.eng, lines.mar\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-FPYgFryUpx",
        "outputId": "6f184084-911a-4f3d-dfe0-d07a41155c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((41267,), (4586,))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch generator**"
      ],
      "metadata": {
        "id": "aweP1LqdXoOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n"
      ],
      "metadata": {
        "id": "7mkwKPvuyUsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder - Decoder Model Architecture:**"
      ],
      "metadata": {
        "id": "YFF3kdhuXsRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 50\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n"
      ],
      "metadata": {
        "id": "ulDiYR6byUux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Triaging model**"
      ],
      "metadata": {
        "id": "Y-m_IiMyXxfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 50\n"
      ],
      "metadata": {
        "id": "Q6o_X7bhyUx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js__4tf9yU0d",
        "outputId": "b4213280-287c-49f7-ed04-842d4439b4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-b22c3ec5e69e>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "322/322 [==============================] - 84s 217ms/step - loss: 0.9773 - acc: 0.1791 - val_loss: 0.8697 - val_acc: 0.2025\n",
            "Epoch 2/50\n",
            "322/322 [==============================] - 65s 203ms/step - loss: 0.8442 - acc: 0.2143 - val_loss: 0.8190 - val_acc: 0.2361\n",
            "Epoch 3/50\n",
            "322/322 [==============================] - 68s 211ms/step - loss: 0.7978 - acc: 0.2478 - val_loss: 0.7835 - val_acc: 0.2594\n",
            "Epoch 4/50\n",
            "322/322 [==============================] - 71s 221ms/step - loss: 0.7626 - acc: 0.2681 - val_loss: 0.7539 - val_acc: 0.2789\n",
            "Epoch 5/50\n",
            "322/322 [==============================] - 66s 206ms/step - loss: 0.7312 - acc: 0.2905 - val_loss: 0.7272 - val_acc: 0.3015\n",
            "Epoch 6/50\n",
            "322/322 [==============================] - 66s 206ms/step - loss: 0.7033 - acc: 0.3115 - val_loss: 0.7054 - val_acc: 0.3199\n",
            "Epoch 7/50\n",
            "322/322 [==============================] - 66s 206ms/step - loss: 0.6780 - acc: 0.3320 - val_loss: 0.6833 - val_acc: 0.3391\n",
            "Epoch 8/50\n",
            "322/322 [==============================] - 66s 206ms/step - loss: 0.6543 - acc: 0.3525 - val_loss: 0.6636 - val_acc: 0.3587\n",
            "Epoch 9/50\n",
            "322/322 [==============================] - 71s 221ms/step - loss: 0.6321 - acc: 0.3713 - val_loss: 0.6458 - val_acc: 0.3737\n",
            "Epoch 10/50\n",
            "322/322 [==============================] - 66s 206ms/step - loss: 0.6119 - acc: 0.3870 - val_loss: 0.6299 - val_acc: 0.3852\n",
            "Epoch 11/50\n",
            "322/322 [==============================] - 66s 204ms/step - loss: 0.5938 - acc: 0.4007 - val_loss: 0.6169 - val_acc: 0.3967\n",
            "Epoch 12/50\n",
            "322/322 [==============================] - 66s 207ms/step - loss: 0.5773 - acc: 0.4145 - val_loss: 0.6040 - val_acc: 0.4067\n",
            "Epoch 13/50\n",
            "322/322 [==============================] - 67s 208ms/step - loss: 0.5618 - acc: 0.4275 - val_loss: 0.5928 - val_acc: 0.4155\n",
            "Epoch 14/50\n",
            "322/322 [==============================] - 67s 207ms/step - loss: 0.5474 - acc: 0.4403 - val_loss: 0.5825 - val_acc: 0.4250\n",
            "Epoch 15/50\n",
            "322/322 [==============================] - 67s 207ms/step - loss: 0.5344 - acc: 0.4519 - val_loss: 0.5725 - val_acc: 0.4319\n",
            "Epoch 16/50\n",
            "322/322 [==============================] - 68s 211ms/step - loss: 0.5209 - acc: 0.4642 - val_loss: 0.5624 - val_acc: 0.4420\n",
            "Epoch 17/50\n",
            "322/322 [==============================] - 67s 208ms/step - loss: 0.5086 - acc: 0.4747 - val_loss: 0.5528 - val_acc: 0.4491\n",
            "Epoch 18/50\n",
            "322/322 [==============================] - 67s 207ms/step - loss: 0.4969 - acc: 0.4849 - val_loss: 0.5444 - val_acc: 0.4572\n",
            "Epoch 19/50\n",
            "322/322 [==============================] - 68s 210ms/step - loss: 0.4866 - acc: 0.4949 - val_loss: 0.5378 - val_acc: 0.4627\n",
            "Epoch 20/50\n",
            "322/322 [==============================] - 69s 214ms/step - loss: 0.4770 - acc: 0.5045 - val_loss: 0.5311 - val_acc: 0.4711\n",
            "Epoch 21/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.4678 - acc: 0.5141 - val_loss: 0.5264 - val_acc: 0.4762\n",
            "Epoch 22/50\n",
            "322/322 [==============================] - 70s 218ms/step - loss: 0.4597 - acc: 0.5229 - val_loss: 0.5224 - val_acc: 0.4777\n",
            "Epoch 23/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.4528 - acc: 0.5305 - val_loss: 0.5174 - val_acc: 0.4859\n",
            "Epoch 24/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.4449 - acc: 0.5386 - val_loss: 0.5136 - val_acc: 0.4885\n",
            "Epoch 25/50\n",
            "322/322 [==============================] - 68s 212ms/step - loss: 0.4377 - acc: 0.5466 - val_loss: 0.5090 - val_acc: 0.4910\n",
            "Epoch 26/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.4310 - acc: 0.5540 - val_loss: 0.5056 - val_acc: 0.4987\n",
            "Epoch 27/50\n",
            "322/322 [==============================] - 69s 215ms/step - loss: 0.4237 - acc: 0.5611 - val_loss: 0.5011 - val_acc: 0.5007\n",
            "Epoch 28/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.4169 - acc: 0.5675 - val_loss: 0.4975 - val_acc: 0.5051\n",
            "Epoch 29/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.4104 - acc: 0.5738 - val_loss: 0.4938 - val_acc: 0.5089\n",
            "Epoch 30/50\n",
            "322/322 [==============================] - 68s 213ms/step - loss: 0.4032 - acc: 0.5804 - val_loss: 0.4898 - val_acc: 0.5126\n",
            "Epoch 31/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.3972 - acc: 0.5859 - val_loss: 0.4861 - val_acc: 0.5152\n",
            "Epoch 32/50\n",
            "322/322 [==============================] - 69s 213ms/step - loss: 0.3916 - acc: 0.5917 - val_loss: 0.4834 - val_acc: 0.5199\n",
            "Epoch 33/50\n",
            "322/322 [==============================] - 69s 215ms/step - loss: 0.3864 - acc: 0.5973 - val_loss: 0.4810 - val_acc: 0.5189\n",
            "Epoch 34/50\n",
            "322/322 [==============================] - 69s 214ms/step - loss: 0.3817 - acc: 0.6022 - val_loss: 0.4780 - val_acc: 0.5220\n",
            "Epoch 35/50\n",
            "322/322 [==============================] - 69s 214ms/step - loss: 0.3777 - acc: 0.6061 - val_loss: 0.4761 - val_acc: 0.5246\n",
            "Epoch 36/50\n",
            "322/322 [==============================] - 69s 214ms/step - loss: 0.3729 - acc: 0.6114 - val_loss: 0.4735 - val_acc: 0.5252\n",
            "Epoch 37/50\n",
            "322/322 [==============================] - 69s 214ms/step - loss: 0.3689 - acc: 0.6156 - val_loss: 0.4722 - val_acc: 0.5265\n",
            "Epoch 38/50\n",
            "322/322 [==============================] - 70s 219ms/step - loss: 0.3650 - acc: 0.6198 - val_loss: 0.4690 - val_acc: 0.5321\n",
            "Epoch 39/50\n",
            "322/322 [==============================] - 69s 214ms/step - loss: 0.3616 - acc: 0.6238 - val_loss: 0.4683 - val_acc: 0.5317\n",
            "Epoch 40/50\n",
            "322/322 [==============================] - 69s 215ms/step - loss: 0.3578 - acc: 0.6276 - val_loss: 0.4659 - val_acc: 0.5335\n",
            "Epoch 41/50\n",
            "322/322 [==============================] - 69s 215ms/step - loss: 0.3544 - acc: 0.6318 - val_loss: 0.4645 - val_acc: 0.5342\n",
            "Epoch 42/50\n",
            "322/322 [==============================] - 70s 217ms/step - loss: 0.3510 - acc: 0.6350 - val_loss: 0.4630 - val_acc: 0.5345\n",
            "Epoch 43/50\n",
            "322/322 [==============================] - 69s 216ms/step - loss: 0.3487 - acc: 0.6377 - val_loss: 0.4617 - val_acc: 0.5382\n",
            "Epoch 44/50\n",
            "322/322 [==============================] - 71s 219ms/step - loss: 0.3447 - acc: 0.6418 - val_loss: 0.4600 - val_acc: 0.5392\n",
            "Epoch 45/50\n",
            "322/322 [==============================] - 70s 217ms/step - loss: 0.3417 - acc: 0.6446 - val_loss: 0.4603 - val_acc: 0.5411\n",
            "Epoch 46/50\n",
            "322/322 [==============================] - 70s 216ms/step - loss: 0.3389 - acc: 0.6473 - val_loss: 0.4596 - val_acc: 0.5390\n",
            "Epoch 47/50\n",
            "322/322 [==============================] - 70s 217ms/step - loss: 0.3362 - acc: 0.6506 - val_loss: 0.4570 - val_acc: 0.5422\n",
            "Epoch 48/50\n",
            "322/322 [==============================] - 70s 218ms/step - loss: 0.3336 - acc: 0.6532 - val_loss: 0.4551 - val_acc: 0.5425\n",
            "Epoch 49/50\n",
            "322/322 [==============================] - 70s 217ms/step - loss: 0.3311 - acc: 0.6558 - val_loss: 0.4553 - val_acc: 0.5419\n",
            "Epoch 50/50\n",
            "322/322 [==============================] - 70s 218ms/step - loss: 0.3287 - acc: 0.6581 - val_loss: 0.4540 - val_acc: 0.5428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62dd3bd0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on Random data**"
      ],
      "metadata": {
        "id": "hAJ_E3_lY-tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n"
      ],
      "metadata": {
        "id": "3Hzis6_jyU3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "metadata": {
        "id": "aQ4zBNSyyU6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Test(test,y):\n",
        "  testt={'new':[test]}\n",
        "  testt=pd.DataFrame(testt)\n",
        "  y_orignal={'new':[y]}\n",
        "  y_orignal=pd.DataFrame(y_orignal)\n",
        "  testt=testt.new.tolist()\n",
        "  y_orignal=y_orignal.new.tolist()\n",
        "  train_gen = generate_batch(testt, y_orignal, batch_size = 1)\n",
        "  (input_seq, actual_output), _ = next(train_gen)\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('Predicted Marathi Translation:', decoded_sentence[:-4])\n",
        "  print('Orignal Marathi Translation:', y)\n"
      ],
      "metadata": {
        "id": "9ltP3Ad0YtYE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test(test='how are you',y='तू कसा आहेस')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT1A6f9kYtbu",
        "outputId": "bf6c5fa8-98b6-4fcb-a311-42f96f8c9c0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted Marathi Translation:  तू कसा आहेस \n",
            "Orignal Marathi Translation: तू कसा आहेस\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test(test='you are welcome',y='तुमचे स्वागत आहे')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPdn-PQZYyrE",
        "outputId": "5102a999-2b2b-4128-f6d3-595087478540"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicted Marathi Translation:  तू उंच आहेस का \n",
            "Orignal Marathi Translation: तुमचे स्वागत आहे\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test(test='can you do this',y='तुम्ही हे करू शकता का')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DspUabZ8Yyu4",
        "outputId": "831ce76f-11c7-457c-8c99-b6176aec5c49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted Marathi Translation:  हे तू करू शकता का \n",
            "Orignal Marathi Translation: तुम्ही हे करू शकता का\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test(test='do you do this',y='तुम्ही हे करता का')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVegCCB0YyxW",
        "outputId": "9039c80b-90e7-428c-b98c-536c3188128f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Marathi Translation:  तू हे का \n",
            "Orignal Marathi Translation: तुम्ही हे करता का\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test(test='would you take tea',y='तू चहा घेशील का')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6pZNRadYy0L",
        "outputId": "11ad3ec7-5384-43ed-94ee-600456a86f3f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Predicted Marathi Translation:  तू चहा हवी का \n",
            "Orignal Marathi Translation: तू चहा घेशील का\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test(test='i saw you yesterday',y='मी तुला काल पाहिले')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFsP4MljYy3e",
        "outputId": "7d002759-8d13-4a80-b17a-eaa721e0e466"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted Marathi Translation:  मी तुला काल पाहिलं \n",
            "Orignal Marathi Translation: मी तुला काल पाहिले\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oB6hiPc6Yy6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}